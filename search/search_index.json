{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Apache Spark SQL DataFrame Symmetric Differ","title":"Home"},{"location":"#apache-spark-sql-dataframe-symmetric-differ","text":"","title":"Apache Spark SQL DataFrame Symmetric Differ"},{"location":"getting-started/","text":"Getting started","title":"Getting started"},{"location":"getting-started/#getting-started","text":"","title":"Getting started"},{"location":"utilities/","text":"diffit Tooling diffit provides a command line utility that you can use to invoke the Apache Spark-based symmetric differential engine. Usage usage: diffit [-h] [-m DRIVER_MEMORY] {schema,row,analyse,columns,convert} ... Diff-it Data Diff tool positional arguments: {schema,row,analyse,columns,convert} schema Diffit schema control row DataFrame row-level diff analyse Diffit rows unique to source DataFrame columns Report only the columns that are different convert CSV to parquet optional arguments: -h, --help show this help message and exit -m DRIVER_MEMORY, --driver_memory DRIVER_MEMORY Set Spark driver memory (default 2g)","title":"diffit Tooling"},{"location":"utilities/#diffit-tooling","text":"diffit provides a command line utility that you can use to invoke the Apache Spark-based symmetric differential engine.","title":"diffit Tooling"},{"location":"utilities/#usage","text":"usage: diffit [-h] [-m DRIVER_MEMORY] {schema,row,analyse,columns,convert} ... Diff-it Data Diff tool positional arguments: {schema,row,analyse,columns,convert} schema Diffit schema control row DataFrame row-level diff analyse Diffit rows unique to source DataFrame columns Report only the columns that are different convert CSV to parquet optional arguments: -h, --help show this help message and exit -m DRIVER_MEMORY, --driver_memory DRIVER_MEMORY Set Spark driver memory (default 2g)","title":"Usage"},{"location":"utilities/diffit/analyse/","text":"diffit analyse diffit analyse supports the concept of a unique constraint key to target differences at the row level. Usage venv/bin/diffit analyse --help usage: diffit analyse [ -h ] [ -R { left,right }] [ -D ] [ -C ] [ -H HITS ] [ -r RANGE ] [ -L LOWER ] [ -U UPPER ] [ -F ] { distinct,altered } key diffit_out positional arguments: { distinct,altered } Report analysis type key column that acts as a unique constraint diffit_out Path to Diffit output options: -h, --help show this help message and exit -R { left,right } , --diffit_ref { left,right } target data source reference -D, --descending Change output ordering to descending -C, --counts Only output counts -H HITS, --hits HITS Rows to display -r RANGE, --range RANGE Column to target for range filter -L LOWER, --lower LOWER Range filter lower bound ( inclusive ) -U UPPER, --upper UPPER Range filter upper bound ( inclusive ) -F, --force-range Force string-based range filter diffit analyse distinct diffit analyse distinct provides a way to report on rows from a Diffit extract that only appear in a specific target data source. Example: Analyse Rows Unique to Each Spark DataFrame Reset the Diffit extract venv/bin/diffit row --output /tmp/out Dummy docker/files/data/left docker/files/data/right The key setting, col01, acts as the GROUP BY predicate venv/bin/diffit analyse distinct col01 /tmp/out Analysing distinct rows from left source DataFrame +-----+-----+----------+ | col01 | col02 | diffit_ref | +-----+-----+----------+ +-----+-----+----------+ Analysing distinct rows from right source DataFrame +-----+-----------+----------+ | col01 | col02 | diffit_ref | +-----+-----------+----------+ | 9 | col02_val09 | right | +-----+-----------+----------+ A Diffit extract can be limited with the --diffit_ref switch. For example, to only show distinct Diffit extract records from the right data source: Analysing distinct rows from right source Spark DataFrame venv/bin/diffit analyse --diffit_ref right distinct col01 /tmp/out Result +-----+-----------+----------+ | col01 | col02 | diffit_ref | +-----+-----------+----------+ | 9 | col02_val09 | right | +-----+-----------+----------+ The default number of rows returned is 20 . This can be adjusted with the --hits switch: venv/bin/diffit analyse --diffit_ref right --hits 5 distinct col01 /tmp/out diffit analyse altered diffit analyse distinct provides a way to report on Diffit extract rows that appear in both target data sources and flagged as being different. Example Given a Diffit extract at /tmp/out that defines a schema column col01 that can act as the unique constraint: Reset the Diffit extract venv/bin/diffit row --output /tmp/out Dummy docker/files/data/left docker/files/data/right venv/bin/diffit analyse altered col01 /tmp/out Result +-----+-----------+----------+ | col01 | col02 | diffit_ref | +-----+-----------+----------+ | 2 | col02_val02 | left | | 2 | col02_valXX | right | +-----+-----------+----------+","title":"diffit analyse"},{"location":"utilities/diffit/analyse/#diffit-analyse","text":"diffit analyse supports the concept of a unique constraint key to target differences at the row level.","title":"diffit analyse"},{"location":"utilities/diffit/analyse/#usage","text":"venv/bin/diffit analyse --help usage: diffit analyse [ -h ] [ -R { left,right }] [ -D ] [ -C ] [ -H HITS ] [ -r RANGE ] [ -L LOWER ] [ -U UPPER ] [ -F ] { distinct,altered } key diffit_out positional arguments: { distinct,altered } Report analysis type key column that acts as a unique constraint diffit_out Path to Diffit output options: -h, --help show this help message and exit -R { left,right } , --diffit_ref { left,right } target data source reference -D, --descending Change output ordering to descending -C, --counts Only output counts -H HITS, --hits HITS Rows to display -r RANGE, --range RANGE Column to target for range filter -L LOWER, --lower LOWER Range filter lower bound ( inclusive ) -U UPPER, --upper UPPER Range filter upper bound ( inclusive ) -F, --force-range Force string-based range filter","title":"Usage"},{"location":"utilities/diffit/analyse/#diffit-analyse-distinct","text":"diffit analyse distinct provides a way to report on rows from a Diffit extract that only appear in a specific target data source.","title":"diffit analyse distinct"},{"location":"utilities/diffit/analyse/#example-analyse-rows-unique-to-each-spark-dataframe","text":"Reset the Diffit extract venv/bin/diffit row --output /tmp/out Dummy docker/files/data/left docker/files/data/right The key setting, col01, acts as the GROUP BY predicate venv/bin/diffit analyse distinct col01 /tmp/out Analysing distinct rows from left source DataFrame +-----+-----+----------+ | col01 | col02 | diffit_ref | +-----+-----+----------+ +-----+-----+----------+ Analysing distinct rows from right source DataFrame +-----+-----------+----------+ | col01 | col02 | diffit_ref | +-----+-----------+----------+ | 9 | col02_val09 | right | +-----+-----------+----------+ A Diffit extract can be limited with the --diffit_ref switch. For example, to only show distinct Diffit extract records from the right data source: Analysing distinct rows from right source Spark DataFrame venv/bin/diffit analyse --diffit_ref right distinct col01 /tmp/out Result +-----+-----------+----------+ | col01 | col02 | diffit_ref | +-----+-----------+----------+ | 9 | col02_val09 | right | +-----+-----------+----------+ The default number of rows returned is 20 . This can be adjusted with the --hits switch: venv/bin/diffit analyse --diffit_ref right --hits 5 distinct col01 /tmp/out","title":"Example: Analyse Rows Unique to Each Spark DataFrame"},{"location":"utilities/diffit/analyse/#diffit-analyse-altered","text":"diffit analyse distinct provides a way to report on Diffit extract rows that appear in both target data sources and flagged as being different.","title":"diffit analyse altered"},{"location":"utilities/diffit/analyse/#example","text":"Given a Diffit extract at /tmp/out that defines a schema column col01 that can act as the unique constraint: Reset the Diffit extract venv/bin/diffit row --output /tmp/out Dummy docker/files/data/left docker/files/data/right venv/bin/diffit analyse altered col01 /tmp/out Result +-----+-----------+----------+ | col01 | col02 | diffit_ref | +-----+-----------+----------+ | 2 | col02_val02 | left | | 2 | col02_valXX | right | +-----+-----------+----------+","title":"Example"},{"location":"utilities/diffit/columns/","text":"diffit columns Report on Spark DataFrame column/value pair differences. Diffit extracts can be large, based on the number of exceptions detected. diffit columns allows you to report on a specific key/value pairing for targeted analysis. Output is displayed as a JSON construct. Usage venv/bin/diffit columns --help usage: diffit columns [ -h ] key val diffit_out positional arguments: key column that acts as a unique constraint val unique constraint column value to filter against diffit_out Path to Diffit output options: -h, --help show this help message and exit Example Given a Diffit extract at /tmp/out that features: A schema column col01 acting as the unique constraint A key column value of 2 as a filter venv/bin/diffit columns col01 2 /tmp/out Result ### col01|2: [ { \"col02\" : \"col02_val02\" } ]","title":"diffit columns"},{"location":"utilities/diffit/columns/#diffit-columns","text":"Report on Spark DataFrame column/value pair differences. Diffit extracts can be large, based on the number of exceptions detected. diffit columns allows you to report on a specific key/value pairing for targeted analysis. Output is displayed as a JSON construct.","title":"diffit columns"},{"location":"utilities/diffit/columns/#usage","text":"venv/bin/diffit columns --help usage: diffit columns [ -h ] key val diffit_out positional arguments: key column that acts as a unique constraint val unique constraint column value to filter against diffit_out Path to Diffit output options: -h, --help show this help message and exit","title":"Usage"},{"location":"utilities/diffit/columns/#example","text":"Given a Diffit extract at /tmp/out that features: A schema column col01 acting as the unique constraint A key column value of 2 as a filter venv/bin/diffit columns col01 2 /tmp/out Result ### col01|2: [ { \"col02\" : \"col02_val02\" } ]","title":"Example"},{"location":"utilities/diffit/convert/","text":"diffit convert Convert as CSV data source with schema file to Spark Parquet to with a given compression (default snappy ) Usage venv/bin/diffit convert --help usage: diffit convert [ -h ] [ -z { brotli,uncompressed,lz4,gzip,lzo,snappy,none,zstd }] schema data_source output positional arguments: schema CSV schema to convert data_source CSV source location output Write parquet to path options: -h, --help show this help message and exit -z { brotli,uncompressed,lz4,gzip,lzo,snappy,none,zstd } , --compression { brotli,uncompressed,lz4,gzip,lzo,snappy,none,zstd } Compression type","title":"diffit convert"},{"location":"utilities/diffit/convert/#diffit-convert","text":"Convert as CSV data source with schema file to Spark Parquet to with a given compression (default snappy )","title":"diffit convert"},{"location":"utilities/diffit/convert/#usage","text":"venv/bin/diffit convert --help usage: diffit convert [ -h ] [ -z { brotli,uncompressed,lz4,gzip,lzo,snappy,none,zstd }] schema data_source output positional arguments: schema CSV schema to convert data_source CSV source location output Write parquet to path options: -h, --help show this help message and exit -z { brotli,uncompressed,lz4,gzip,lzo,snappy,none,zstd } , --compression { brotli,uncompressed,lz4,gzip,lzo,snappy,none,zstd } Compression type","title":"Usage"},{"location":"utilities/diffit/row/","text":"diffit row diffit row reporter acts on two similarly constructed Spark Parquet output sources. These are denoted as left and right . Differences are reported at the row level. Another way to think about the diffit row reporter is that identical rows from the left and right data sources are suppressed from the output. diffit row will produce a Diffit extract that is a Spark DataFrame in Spark Parquet format. The Diffit extract can then be further analysed using other diffit subcommands see diffit analyse or with any other tooling that supports parquet. A key characteristic of the Diffit extract is that it features a new column diffit_ref . This denotes the source reference that has caused the row level exception. Typically, this value will be either left or right . Usage venv/bin/diffit row --help usage: diffit row [ -h ] [ -o OUTPUT ] [ -d [ DROP ... ]] [ -r RANGE ] [ -L LOWER ] [ -U UPPER ] [ -F ] schema left_data_source right_data_source positional arguments: schema Report schema left_data_source \"Left\" DataFrame source location right_data_source \"Right\" DataFrame source location options: -h, --help show this help message and exit -o OUTPUT, --output OUTPUT Write results to path -d [ DROP ... ] , --drop [ DROP ... ] Drop column from diffit engine -r RANGE, --range RANGE Column to target for range filter -L LOWER, --lower LOWER Range filter lower bound ( inclusive ) -U UPPER, --upper UPPER Range filter upper bound ( inclusive ) -F, --force-range Force string-based range filter Example A sample data set has been provided for the Dummy schema. This can be invoked as follows: venv/bin/diffit row --output /tmp/out Dummy docker/files/data/left docker/files/data/right Use the local pyspark shell to view the results: make pyspark >>> df = spark.read.parquet ( '/tmp/out' ) >>> df.orderBy ( 'col01' ) .show () +-----+-----------+----------+ | col01 | col02 | diffit_ref | +-----+-----------+----------+ | 2 | col02_val02 | left | | 2 | col02_valXX | right | | 9 | col02_val09 | right | +-----+-----------+----------+ Example: Report on Subset of Spark DataFrame Columns diffit can be run on a subset of DataFrame columns. This can limit the symmetric difference checker to a reduced number of colums for more targeted, efficient processing. To remove one or more unwanted Spark DataFrame columns use the drop switch. For example, to drop col02 from the local test sample: venv/bin/diffit row --output /tmp/out --drop col02 -- Dummy docker/files/data/left docker/files/data/right To view the results: make pyspark >>> df = spark.read.parquet ( '/tmp/out' ) >>> df.show () +-----+----------+ | col01 | diffit_ref | +-----+----------+ | 9 | right | +-----+----------+ Multiple columns can be added to the drop switch separated by spaces. For example: ... --drop col01 col02 ... col<n> -- Example: Column Value Range Filtering Note Only pyspark.sql.types.IntegerType is currently supported. Filtering can be useful to limit diffit to a subset of the original Spark SQL DataFrame. For example, we can limit the test data sources under docker/files/data/left to remove col01 values 3 and above as follows: venv/bin/diffit row --output /tmp/out --range col01 --lower 1 --upper 2 -- Dummy docker/files/data/left docker/files/data/right To view the results: make pyspark >>> df = spark.read.parquet ( '/tmp/out' ) >>> df.orderBy ( 'col01' ) .show () +-----+-----------+----------+ | col01 | col02 | diffit_ref | +-----+-----------+----------+ | 2 | col02_valXX | right | | 2 | col02_val02 | left | +-----+-----------+----------+","title":"diffit row"},{"location":"utilities/diffit/row/#diffit-row","text":"diffit row reporter acts on two similarly constructed Spark Parquet output sources. These are denoted as left and right . Differences are reported at the row level. Another way to think about the diffit row reporter is that identical rows from the left and right data sources are suppressed from the output. diffit row will produce a Diffit extract that is a Spark DataFrame in Spark Parquet format. The Diffit extract can then be further analysed using other diffit subcommands see diffit analyse or with any other tooling that supports parquet. A key characteristic of the Diffit extract is that it features a new column diffit_ref . This denotes the source reference that has caused the row level exception. Typically, this value will be either left or right .","title":"diffit row"},{"location":"utilities/diffit/row/#usage","text":"venv/bin/diffit row --help usage: diffit row [ -h ] [ -o OUTPUT ] [ -d [ DROP ... ]] [ -r RANGE ] [ -L LOWER ] [ -U UPPER ] [ -F ] schema left_data_source right_data_source positional arguments: schema Report schema left_data_source \"Left\" DataFrame source location right_data_source \"Right\" DataFrame source location options: -h, --help show this help message and exit -o OUTPUT, --output OUTPUT Write results to path -d [ DROP ... ] , --drop [ DROP ... ] Drop column from diffit engine -r RANGE, --range RANGE Column to target for range filter -L LOWER, --lower LOWER Range filter lower bound ( inclusive ) -U UPPER, --upper UPPER Range filter upper bound ( inclusive ) -F, --force-range Force string-based range filter","title":"Usage"},{"location":"utilities/diffit/row/#example","text":"A sample data set has been provided for the Dummy schema. This can be invoked as follows: venv/bin/diffit row --output /tmp/out Dummy docker/files/data/left docker/files/data/right Use the local pyspark shell to view the results: make pyspark >>> df = spark.read.parquet ( '/tmp/out' ) >>> df.orderBy ( 'col01' ) .show () +-----+-----------+----------+ | col01 | col02 | diffit_ref | +-----+-----------+----------+ | 2 | col02_val02 | left | | 2 | col02_valXX | right | | 9 | col02_val09 | right | +-----+-----------+----------+","title":"Example"},{"location":"utilities/diffit/row/#example-report-on-subset-of-spark-dataframe-columns","text":"diffit can be run on a subset of DataFrame columns. This can limit the symmetric difference checker to a reduced number of colums for more targeted, efficient processing. To remove one or more unwanted Spark DataFrame columns use the drop switch. For example, to drop col02 from the local test sample: venv/bin/diffit row --output /tmp/out --drop col02 -- Dummy docker/files/data/left docker/files/data/right To view the results: make pyspark >>> df = spark.read.parquet ( '/tmp/out' ) >>> df.show () +-----+----------+ | col01 | diffit_ref | +-----+----------+ | 9 | right | +-----+----------+ Multiple columns can be added to the drop switch separated by spaces. For example: ... --drop col01 col02 ... col<n> --","title":"Example: Report on Subset of Spark DataFrame Columns"},{"location":"utilities/diffit/row/#example-column-value-range-filtering","text":"Note Only pyspark.sql.types.IntegerType is currently supported. Filtering can be useful to limit diffit to a subset of the original Spark SQL DataFrame. For example, we can limit the test data sources under docker/files/data/left to remove col01 values 3 and above as follows: venv/bin/diffit row --output /tmp/out --range col01 --lower 1 --upper 2 -- Dummy docker/files/data/left docker/files/data/right To view the results: make pyspark >>> df = spark.read.parquet ( '/tmp/out' ) >>> df.orderBy ( 'col01' ) .show () +-----+-----------+----------+ | col01 | col02 | diffit_ref | +-----+-----------+----------+ | 2 | col02_valXX | right | | 2 | col02_val02 | left | +-----+-----------+----------+","title":"Example: Column Value Range Filtering"},{"location":"utilities/diffit/schema/","text":"diffit schema List all native CSV schemas use the diffit schema subcommand. Usage venv/bin/diffit schema --help usage: diffit schema [-h] {list} ... positional arguments: {list} list List supported schemas options: -h, --help show this help message and exit Example diffit provides a sample CSV schema, Dummy , that can be used for evaluation purposes: venv/bin/diffit schema list 1. Dummy","title":"diffit schema"},{"location":"utilities/diffit/schema/#diffit-schema","text":"List all native CSV schemas use the diffit schema subcommand.","title":"diffit schema"},{"location":"utilities/diffit/schema/#usage","text":"venv/bin/diffit schema --help usage: diffit schema [-h] {list} ... positional arguments: {list} list List supported schemas options: -h, --help show this help message and exit","title":"Usage"},{"location":"utilities/diffit/schema/#example","text":"diffit provides a sample CSV schema, Dummy , that can be used for evaluation purposes: venv/bin/diffit schema list 1. Dummy","title":"Example"}]}